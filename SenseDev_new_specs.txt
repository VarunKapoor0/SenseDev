SenseDev: Code Snippet Extraction & AI Context Builder Specification

Version 1.0 — Required Components for Complete Code-Aware AI

Purpose

This document defines the missing but required architectural components needed for SenseDev to fully support code-level AI reasoning using commercial LLMs (e.g., Gemini 2.x).

SenseDev currently passes only graph metadata to the AI provider.
To produce accurate, code-aware answers, SenseDev must implement:

A File Locator

A Code Snippet Extractor

A Code Truncation & Normalization Engine

An AI Context Builder

A Gemini 2.x Multi-Part Prompt Encoder

A Provider-Aware Capability Layer

Each component is required for SenseDev to evolve from “graph-only answers” → “deep code understanding”.

1. High-Level Data Flow
User Question
      ↓
Identify Relevant Nodes
      ↓
Locate Corresponding Files
      ↓
Extract Code Snippets (Tiered)
      ↓
Normalize & Truncate Code
      ↓
Build AI Context Package
      ↓
Encode for Gemini 2.x (multipart)
      ↓
Gemini Provider API
      ↓
LLM Response
      ↓
Parse Multi-Format Responses
      ↓
Display Answer + Highlight Nodes/Files


This pipeline must be implemented correctly for SenseDev to deliver meaningful responses.

2. Component 1 — File Locator
2.1 Purpose

Given a graph node (e.g., “MainActivity”) or class name, determine:

The exact file path

The project module it belongs to

Kotlin vs Java determination

Whether the file exists

2.2 Required Inputs

Node metadata from static analysis:

className

packageName

filePath (if static analysis already mapped it)

Full project directory index (generated at project load)

2.3 Behavior

Primary lookup
Match using the known file path from analysis.

Secondary lookup
Search project index:

/src/main/java/**/MainActivity.kt
/src/main/kotlin/**/MainActivity.kt


Fallback lookup
Fuzzy match by class declaration:

Scan .kt/.java files containing:

class MainActivity

object MainActivity

@Composable fun MainActivity

Helpful for Compose.

If multiple files match → choose best via:

Strongest package match

Closest lexical match

Using project’s package graph

2.4 Output
data class LocatedFile(
    val absolutePath: String,
    val relativePath: String,
    val fileContent: String
)

3. Component 2 — Code Snippet Extractor
3.1 Purpose

Extract code for the AI to analyze based on the selected node and the user’s access mode.

3.2 Modes
Mode A: Snippet-Only (Safe Default)

Extract only:

The class body

The selected method

Directly relevant companion object content

Mode B: Flow-Based Snippets

For flows like sensor pipelines:

Extract class/method bodies for all nodes in the flow

Provide them in separate block-labeled segments

Combine in ascending order of causal flow

Mode C: Full File Access

The entire file content, truncated intelligently.

3.3 Extraction Method

Read file content

Identify class boundaries using regex or PSI-based parsing:

class <ClassName> {...}


Identify method bodies:

fun <methodName>(...) {...}


Extract surrounding context (imports / typealiases / companion objects)

3.4 Output Format (raw)
[FILE: app/src/.../MainActivity.kt]
class MainActivity : ComponentActivity() {
    override fun onCreate(...) {
        ...
    }
}

4. Component 3 — Code Truncation & Normalization Engine
4.1 Purpose

Ensure AI input stays within token limits while maximizing relevant code content.

4.2 Steps
1. Remove Comments (Optional)

Large comment blocks are trimmed unless relevant.

2. Remove Blank Lines / Excessive Whitespace
3. Collapse Long Blocks

Replace arrays or long literal blocks with:

/* ... array truncated ... */

4. Truncate Around Relevance

Prefer the parts surrounding:

Class declaration

Lifecycle methods

Sensor listeners

Flow collectors

5. Upper Token Limit Enforcement

Example defaults:

Snippet-only: 300–600 tokens

Flow-level: 1500 tokens

Full file: 4000–6000 tokens

4.3 Output
String normalizedCode

5. Component 4 — AI Context Builder
5.1 Purpose

Create structured multi-part messages for Gemini 2.x models.

5.2 Required Inputs

User question

Selected node

Graph context summary

Code snippets

Code access level

Model type (Gemini 2.0 / 2.5)

5.3 Prompt Structure (Multi-Part Required)
contents: [
  {
    parts: [
      { text: "User question: $question" },
      { text: "Graph context: $graphSummary" },
      { text: "Relevant code snippet(s):" },
      { text: codeSnippet },
      { text: "Instructions: You must reference ONLY the provided code." }
    ]
  }
]

5.4 Special Instructions

Do not hallucinate missing files

If unknown, say “This cannot be determined from the provided code.”

Link reasoning to specific lines

Prefer deterministic answers

Use clear technical explanations

5.5 Output
data class AIContext(
    val parts: List<String>,
    val model: String
)

6. Component 5 — Gemini 2.x Multi-Part Encoder
6.1 Purpose

Convert AIContext into the official Gemini 2.x API format.

6.2 Requirements

Use v1beta/models/{model}:generateContent

Use contents[].parts[]

Each part must be a separate block

6.3 Example JSON
{
  "contents": [
    {
      "parts": [
        { "text": "User question: What does MainActivity do?" },
        { "text": "Graph context summary..." },
        { "text": "Relevant code:" },
        { "text": "class MainActivity {...}" }
      ]
    }
  ]
}

6.4 Failure Handling

AI returns no candidates → fallback

API 404 → show “Model unsupported”

API 429 → rate limit messaging

7. Component 6 — Provider Capability Layer
Purpose

Different providers have different abilities and input formats.

SenseDev must maintain a registry:

AIProviderCapabilities(
    maxContextTokens: Int,
    allowsMultipart: Boolean,
    supportsKotlinCodeReasoning: Boolean,
    supportsFileContext: Boolean,
    responseFormats: List<LLMResponseFormat>
)


Used to:

Adjust prompt strategy

Select fallback model

Validate max payload size

Use correct deserializer

8. Failure Modes & Expected Behavior
8.1 If File Extraction Fails

Respond:

Cannot analyze this file because it could not be located.

8.2 If Code Snippet Is Empty

Respond:

Cannot answer this question without relevant source code.

8.3 If Truncation Removes Too Much Code

Respond:

Provided code is insufficient to determine the requested behavior.

8.4 If AI Returns Unsupported Format

Respond:

This model returned an unsupported response structure.

9. Summary of Requirements

To enable deep AI reasoning:

SenseDev MUST implement:

File locator

Code extractors

Token-aware truncation

Multi-part prompt builder

Gemini 2.x encoder

Capability-aware provider layer

Commercial AI MUST support:

Code reasoning

Multi-file context

Multi-part message inputs

Large token contexts

Non-hallucinatory, grounded outputs

With these components implemented, SenseDev will be able to answer questions like:

“How does sensor data propagate through the pipeline?”

“Why might this cause a memory leak?”

“Where is the motion state mutated?”

“Explain what MainActivity actually does.”